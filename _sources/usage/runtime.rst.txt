BMRuntime 使用
================

BMRUNTIME用于读取BMCompiler的编译输出(.bmodel)，驱动其在BITMAIN TPU芯片中执行。BMRUNTIME向用户提供了丰富的接口，便于用户移植算法，其软件架构如下:

.. image:: ../_static/bmruntime.png


C Interface (Base)
_____________________

基本的BMRuntime接口采用C语言，对应的头文件为bmruntime_interface.h，对应的lib库为libbmrt.so。

Create bmruntime
>>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void* create_bmrt_helper(void *pbm_handle, const char *chip_type, int devid);

This API creates the bmruntime. It returns a void* pointer which is the pointer of bmruntime. This API can set device id.

:Parameters: - **[in/out] pbm_handle** - BM runtime context. It is input if it had been created before. If it is NULL, it will be created as the output. This context is for using BMDNN and BMCV.
             - **[in] chip_type** - Chipname, such as BM1682_PCIE, BM1682_SOC, BM1682_PCIE, BM1684_SOC.
             - **[in] devid** - ID of device.

:Returns:    - **p_bmrt** - The pointer of bmruntime

.. code-block:: c++

  #define create_bmruntime(pbm_handle, chip_type, ...) create_bmrt_helper(pbm_handle, chip_type, (0, ##__VA_ARGS__))

This API creates the bmruntime. It returns a void* pointer which is the pointer of bmruntime. This API default uses the 0-th device.

Destroy bmruntime
>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void destroy_bmruntime(void* p_bmrt);

This API destroys the bmruntime.

:Parametets: - **[in] p_bmrt** - Bmruntime that had been created.

Load bmodel
>>>>>>>>>>>>>>>>

.. code-block:: c++

  bool bmrt_load_bmodel(void* p_bmrt, const char *bmodel_path);
 
This API is to load bmodel created by BM compiler. After loading bmodel, we can run the inference of neuron network. Different with bmrt_load context, bmodel is a file. Bmodel is the pack of the context.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
             - **[in] bmodel_path** - Bmodel file directory.

:Returns:    - **bool** - true: load bmodel success; false: load bmodel failed.


Show neuron network
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_show_neuron_network(void* p_bmrt);

To print the name of all neuron network

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created

Get network number
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_get_network_number(void* p_bmrt);

To get the number of neuron network in the bmruntime

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created

:Returns:    - **int** - The number of neuron networks.

Get network names
>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_get_network_names(void* p_bmrt, const char*** network_names);

To get the names of all neuron network in the bmruntime

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] network_names** - The names of all neuron networks. It should be declare as (const char** networks = NULL), and use as the param &networks_. After this API, user need to free(networks) if user do not need it.

Get network index
>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_get_network_index(void* p_bmrt, const char* net_name);

To get the index of a network.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
             - **[in] net_name** - The names of the neuron network.

:Returns:    - **int** - The index of the network

Get input tensors
>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_get_input_tensor(void* p_bmrt, int net_idx, const char *net_name, int *input_num, const char ***input_names);

This API can get the input number and input name of a neuron network. This API can be used after loading context or bmodel.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created. 
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to disable it.
             - **[out] input_num** - The input number of the neuron network.
             - **[out] input_names** - The input names of the neruon network. When we use this API, we can declare (const char** inputs = NULL), then use &inputs as this parameter. Bmruntime will create space for inputs, and we need to free(inputs) if we do not use it.

Get output tensors
>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_get_output_tensor(void* p_bmrt, int net_idx, const char *net_name, int *output_num, const char ***output_names);

This API can get the output number and output name of a neuron network. This API can only be used after loading context or bmodel.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created 
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
             - **[out] output_num** - The output number of the neuron network.
             - **[out] output_names** - The output names of the neruon network. When we use this API, we can declare (const char** outputs = NULL), then use &outputs as this parameter. Bmruntime will create space for outputs, and we need to free(outputs) if we do not use it.

Get input shape
>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_get_input_blob_max_nhw(void* p_bmrt, const char *tensor_name,
                                   int net_idx, const char *net_name,
                                   int * max_n, int * max_c, int * max_h, int * max_w);

To get the max shape of the tensor. This API must indicate the name of the input tensor and neuron network. When using the neuron network that is static-compiled once, max shape is the real shape of the neuron netork. When using the neuron network that is dynamic-compiled, max shape is max value we can set.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
            - **[in] tensor_name** - The name of the tensor.
            - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
            - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
            - **[out] max_n** - The max batch number of the tensor.
            - **[out] max_c** - The max channels of the tensor.
            - **[out] max_h** - The max height of the tensor.
            - **[out] max_w** - The max width of the tensor.




Get output shape
>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_get_output_blob_max_nhw(void* p_bmrt, const char *tensor_name,
                                    int net_idx, const char *net_name,
                                    int * max_n, int * max_c, int * max_h, int * max_w);

To get the max shape of the tensor. This API must indicate the name of the output tensor and neuron network. When using the neuron network that is static-compiled once, max shape is the real shape of the neuron netork. When using the neuron network that is dynamic-compiled, max shape is max value we can set.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
            - **[in] tensor_name** - The name of the tensor.
            - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
            - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
            - **[out] max_n** - The max batch number of the tensor.
            - **[out] max_c** - The max channels of the tensor.
            - **[out] max_h** - The max height of the tensor.
            - **[out] max_w** - The max width of the tensor.


.. code-block:: c++

  int bmrt_get_accurate_output_channel(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);
  int bmrt_get_accurate_output_height(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);
  int bmrt_get_accurate_output_width(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);


To get the output channel, height and width. **Note:** These API must be called after inference launch. It will block cpu program to wait for the finishing of network inference if the neuron network is dynamic-compiled.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] tensor_name** - The name of the tensor
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:    - **int** - The channels/height/width of the output tensor.


Get input data type
>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_get_input_data_type(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);

To get the data type of the input tensor. The API is to get the data type of the tensor. Data type include float32, float16, int8, uint8, int16, uint16.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
             - **[in] tensor_name** - The name of the tensor.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:    - **int** - 0: float32, 1: float16, 2: int8, 3: uint8, 4: int16, 5: uint16. 


Get output data type
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_get_output_data_type(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);

To get the data type of the output tensor. The API is to get the data type of the tensor. Data type include float32, float16, int8, uint8, int16, uint16.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
             - **[in] tensor_name** - The name of the tensor.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:    - **int** - 0: float32, 1: float16, 2: int8, 3: uint8, 4: int16, 5: uint16. 


Get input store mode
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_get_input_gmem_stmode(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);

To get the data store mode of the input tensor. The API is to get the data store mode of the tensor. Data store mode includes 1N mode, 2N mode, 4N mode. 1N mode is the normal store mode we know.

Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
            - **[in] tensor_name** - The name of the tensor.
            - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
            - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:   - **int** - 0: 1N, 1: 2N, 2: 4N


Get output store mode
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_get_output_gmem_stmode(void* p_bmrt, const char *tensor_name, int net_idx, const char *net_name);

To get the data store mode of the output tensor. The API is to get the data store mode of the tensor. Data store mode includes 1N mode, 2N mode, 4N mode. 1N mode is the normal store mode we know.

Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
            - **[in] tensor_name** - The name of the tensor.
            - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
            - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:   - **int** - 0: 1N, 1: 2N, 2: 4N

Input shape change
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  bool bmrt_can_batch_size_change(void* p_bmrt, int net_idx, const char *net_name);

To judge if the neuron network after compiling can change batch size.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:    - **bool** - ture: The neuron network after compiling can change batch size. false: The neuron network after compiling can not change batch size.


.. code-block:: c++

  bool bmrt_can_height_and_width_change(void* p_bmrt, int net_idx, const char *net_name);

To judge if the neuron network after compiling can change input height and width

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.

:Returns:    - **bool** - ture: The neuron network after compiling can change input height and width. false: The neuron network after compiling can not change input height and width.


Launch computation
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  bool bmrt_launch_nhw(void* p_bmrt, int net_idx, const char *net_name,
                       const void* input_tensors, int input_num,
                       const void* output_tensors, int output_num,
                       int n, int h, int w);

To launch the inference of the neuron network with setting input n, h, w. This API supports the neuron nework that is static-compiled or dynamic-compiled. After calling this API, inference on TPU is launched. And the CPU
program will not be blocked. **Note:** This API only support one input

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
             - **[in] input_tensors** - The pointer of the input devce memory. It should be bm_device_mem_t*. input_tensors[i] must be created by malloc device memory.
             - **[in] input_num** - The input number of the neuron network.
             - **[out] output_tensors** - The pointer of the output devce memory. It should be bm_device_mem_t*. output_tensors[i] must be created by malloc device memory.
             - **[in] output_num** - The output number of the neuron network.
             - **[in] n** - The batch number of the neuron network.
             - **[in] h** - The input height of the neuron network.
             - **[in] w** - The input width of the neuron network.

:Returns:    - **bool** - true: Launch success. false: Launch failed.


.. code-block:: c++

  bool bmrt_launch_shape(void* p_bmrt, int net_idx, const char *net_name,
                         const void* input_tensors, int input_num,
                         const int* input_dim, const int* input_shape,
                         const void* output_tensors, int output_num);

To launch the inference of the neuron network with setting input shape. This API supports the neuron nework that is static-compiled or dynamic-compiled. After calling this API, inference on TPU is launched. And the CPU
program will not be blocked. This API support multiple inputs.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
             - **[in] input_tensors** - The pointer of the input devce memory. It should be bm_device_mem_t*. input_tensors[i] must be created by malloc device memory.
             - **[in] input_num** - The input number of the neuron network.
             - **[out] output_tensors** - The pointer of the output devce memory. It should be bm_device_mem_t*. output_tensors[i] must be created by malloc device memory.
             - **[in] output_num** - The output number of the neuron network.
             - **[in] input_dim** - The dimension of each input.
             - **[in] input_shape** - The shape of each input. If the dimension of the i-th input is x, input_shape[i] has x elements. For example, 4 dimension will has 4 elements, input_shape[i][0] is N, input_shape[i][1] is C, input_shape[i][2] is H, input_shape[i][3] is W.

:Returns:    - **bool** - true: Launch success. false: Launch failed.


.. code-block:: c++

  bool bmrt_launch_cpu_data(void* p_bmrt, int net_idx, const char *net_name,
                       void* input_tensors, int input_num,
                       void* output_tensors, int output_num,
                       const int* in_shape, int* out_shape);

To launch the inference of the neuron network with cpu data. This API supports the neuron nework that is static-compiled or dynamic-compiled. After calling this API, inference on TPU is launched. And the CPU program will be blocked.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created
             - **[in] net_idxi** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
             - **[in] input_tensors** - The cpu pointer of the input.
             - **[in] input_num** - The input number of the neuron network.
             - **[out] output_tensors** - The cpu pointer of the output.
             - **[in] output_num** - The output number of the neuron network.
             - **[in] in_shape** - The input shape of the neuron network. Support multiple inputs. shape format (net0_n, net0_c, net0_h, net0_w, net1_n, net1_c, net1_h, net1_w)
             - **[out] out_shape** - The output shape of the neuron network. Support multiple outputs. Bmruntime will set out_shape.

:Returns:    - **bool** - true: Launch success. false: Launch failed.


.. code-block:: c++

  bool bmrt_launch_nhw_stmode(void* p_bmrt, int net_idx, const char *net_name,
                              const void* input_tensors, int input_num,
                              const void* output_tensors, int output_num,
                              int n, int h, int w,
                              int* in_stmode, int* out_stmode);


To launch the inference of the neuron network with setting input n/h/w and store mode. This API supports the neuron nework that is static-compiled or dynamic-compiled. After calling this API, inference on TPU is launched. And the CPU. program will not be blocked. **Note:** This API only support one input of the neuron network.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
             - **[in] input_tensors** - The pointer of the input devce memory. It should be bm_device_mem_t*. input_tensors[i] must be created by malloc device memory.
             - **[in] input_num** - The input number of the neuron network.
             - **[out] output_tensors** - The pointer of the output devce memory. It should be bm_device_mem_t*. output_tensors[i] must be created by malloc device memory.
             - **[in] output_num** - The output number of the neuron network.
             - **[in] n** - The batch number of the neuron network.
             - **[in] h** - The input height of the neuron network.
             - **[in] w** - The input width of the neuron network.
             - **[in] in_stmode** - User define the store mode of the input.
             - **[in] out_stmode** - User define the store mode of the output.

:Returns:    - **bool** - true: Launch success. false: Launch failed.


.. code-block:: c++

  bool bmrt_launch_shape_stmode(void* p_bmrt, int net_idx, const char *net_name,
                                const void* input_tensors, int input_num,
                                const int* input_dim, const int* input_shape,
                                const void* output_tensors, int output_num,
                                int* in_stmode, int* out_stmode);

To launch the inference of the neuron network with setting input shape and store mode. This API supports the neuron nework that is static-compiled or dynamic-compiled After calling this API, inference on TPU is launched. And the CPU program will not be blocked. This API support multiple inputs of the neuron network.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] net_idx** - Neuron network index of the context. This parameter is enable if net_name == NULL, otherwise it is disable.
             - **[in] net_name** - The name of the neuron network. It can be NULL if we want to use net_idx.
             - **[in] input_tensors** - The pointer of the input devce memory. It should be bm_device_mem_t*. input_tensors[i] must be created by malloc device memory.
             - **[in] input_num** - The input number of the neuron network.
             - **[out] output_tensors** - The pointer of the output devce memory. It should be bm_device_mem_t*. output_tensors[i] must be created by malloc device memory.
             - **[in] output_num** - The output number of the neuron network.
             - **[in] input_dim** - The dimension of each input.
             - **[in] input_shape** - The shape of each input. If the dimension of the i-th input is x, input_shape[i] has x elements. For example, 4 dimension will has 4 elements, input_shape[i][0] is N, input_shape[i][1] is C, input_shape[i][2] is H, input_shape[i][3] is W.
             - **[in] in_stmode** - User define the store mode of the input.
             - **[in] out_stmode** - User define the store mode of the output.

:Returns:    - **bool** - true: Launch success. false: Launch failed.


Malloc device memory
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  int bmrt_malloc_device_byte(void* p_bmrt, bm_device_mem_t *pmem, unsigned int size);

To allocate device memory by byte size.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] pmem** - Device memory. If use declare device memory as (bm_device_mem_t mem), use it as parameter (&mem).
             - **[in] size** - The number of byte.

:Returns:    - **int** - 0: Success. other: fail.


.. code-block:: c++

  int bmrt_malloc_neuron_device(void* p_bmrt, bm_device_mem_t *pmem, int n, int c, int h, int w);

To allocate device memory by neuron. The size of the device memory by this API is (n * c * h * w * sizeof(float))

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] pmem** - Device memory. If use declare device memory as (bm_device_mem_t mem), use it as parameter (&mem).
             - **[in] n** - The batch size.
             - **[in] c** - The channels.
             - **[in] h** - The height.
             - **[in] w** - The width.

:Returns:    - **int** - 0: Success. other: fail.


Free device memory
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++

  void bmrt_free_device(void* p_bmrt, bm_device_mem_t mem);

To free the device memory.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[in] pmem** - Device memory. If use declare device memory as (bm_device_mem_t mem), use it as parameter (&mem).

Data copy
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++
  
  int bmrt_memcpy_s2d(void* p_bmrt, bm_device_mem_t dst, void* src);

To copy data from system to device. The system memory is allocated by user. The data size transfered by this API is equal to the device memory capacity that user had allocated.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] dst** - destination device memory.
             - **[in] src** - Source system memory.

:Returns:    - **int** - 0: Success. other: fail.


.. code-block:: c++
  
  int bmrt_memcpy_d2s(void* p_bmrt, void *dst, bm_device_mem_t src);

To copy data from device to system. The system memory is allocated by user. The data size transfered by this API is equal to the device memory capacity that user had allocated.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] dst** - destination system memory.
             - **[in] src** - Source device memory.

:Returns:    - **int** - 0: Success. other: fail.


.. code-block:: c++
  
  int bmrt_memcpy_s2d_withsize(void* p_bmrt, bm_device_mem_t dst, void* src, unsigned int size);

To copy data from system to device with setting size. The system memory is allocated by user. The data size transfered by this API can be set by user.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] dst** - destination device memory.
             - **[in] src** - Source system memory.
             - **[in] size** - The byte size.

:Returns:    - **int** - 0: Success. other: fail.


.. code-block:: c++
  
  int bmrt_memcpy_d2s_withsize(void* p_bmrt, void *dst, bm_device_mem_t src, unsigned int size);


To copy data from device to system with setting size. The system memory is allocated by user. The data size transfered by this API can be set by user.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] dst** - destination system memory.
             - **[in] src** - Source device memory.
             - **[in] size** - The byte size.

:Returns:    - **int** - 0: Success. other: fail.


.. code-block:: c++
  
  int bmrt_memcpy_s2d_withsize_offset(void* p_bmrt, bm_device_mem_t dst, void* src, unsigned int size, unsigned int dev_offset);

To copy data from system to device with setting size and device memory offset. The system memory is allocated by user. The data size transfered by this API can be set by user. And device memory offset can be also set by user. Data from device memory (address + offset) is transfered.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] dst** - destination device memory.
             - **[in] src** - Source system memory.
             - **[in] size** - The byte size.
             - **[in] dev_offset** - Offset of device memory. Unit is byte.

:Returns:    - **int** - 0: Success. other: fail.


.. code-block:: c++
  
  int bmrt_memcpy_d2s_withsize_offset(void* p_bmrt, void *dst, bm_device_mem_t src, unsigned int size, unsigned int dev_offset);

To copy data from device to system with setting size and device memory offset. The system memory is allocated by user. The data size transfered by this API can be set by user. And device memory offset can be also set by user. Data from device memory (address + offset) is transfered.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.
             - **[out] dst** - destination system memory.
             - **[in] src** - Source device memory.
             - **[in] size** - The byte size.
             - **[in] dev_offset** - Offset of device memory. Unit is byte.

:Returns:    - **int** - 0: Success. other: fail.


Program synchronize
>>>>>>>>>>>>>>>>>>>>>>

.. code-block:: c++
  
  int bmrt_thread_sync(void* p_bmrt);

To synchronize cpu program to device. This API is called when user program want to wait for the finishing of device.

:Parameters: - **[in] p_bmrt** - Bmruntime that had been created.

:Returns:    - **int** - 0: Success. other: fail.


C++ Interface (Caffe like)
____________________________

类Caffe的Inference C++接口。对应的头文件为bmblob.h, bmcnnctx.h, bmnet.h，对应的lib库为libbmrt.so。详细接口和注解请见bmblob.h, bmcnnctx.h, bmnet.h。



  
